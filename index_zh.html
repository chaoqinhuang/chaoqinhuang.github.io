<!DYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chaoqin Huang</title>
  
  <meta name="author" content="Chaoqin Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> 黄潮钦 (Chaoqin Huang)</name>
              </p>
              <p>国防科技大学助理教授。2024年博士毕业于<a href="https://mediabrain.sjtu.edu.cn/">上海交通大学</a> 和<a href="http://www.lv-nus.org/">新加坡国立大学</a>（导师：<a href="https://mediabrain.sjtu.edu.cn/yazhang/">张娅教授</a>、<a href="https://sites.google.com/site/sitexinchaowang/">王鑫超助理教授</a>）。2021年4月-2024年6月，在上海人工智能实验室担任见习研究员。2019年本科毕业于上海交通大学，计算机科学与技术专业，期间在MVIG实验室担任助研（导师：<a href="https://scholar.google.com.hk/citations?user=QZVQEWAAAAAJ&hl=zh-CN">卢策吾教授</a>）。
              </p>
	      <p>
		      研究兴趣：人工智能、计算机视觉、异常检测。
              </p>      
              <a href="chaoqinhuang.pdf">简历</a> &nbsp/&nbsp
              <a href="mailto:huangchaoqin@sjtu.edu.cn">邮箱</a> &nbsp/&nbsp
              <a href="https://scholar.google.com/citations?user=BAZSE7wAAAAJ&hl=en">谷歌学术</a> &nbsp/&nbsp
              <a href="https://github.com/chaoqinhuang">Github</a> &nbsp/&nbsp
              <a href="./index.html">English Homepage (英文主页)</a>
              <p style="text-align:center">
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/chaoqinhuang01.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="image/chaoqinhuang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
	

  
</tbody></table>
	<br />
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>荣誉奖项</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="0"><tbody>
            <li> [2023/06]: <a href="https://sites.google.com/view/vand-cvpr23/challenge">VAND @ CVPR 2023</a> 挑战赛全球亚军<br> 
            <li> [2022/12]: <strong>博士国家奖学金</strong><br> 
            <li> [2022/12]: 入选吴文俊人工智能荣誉博士班<br> 
            <li> [2019/06]: 上海交通大学优秀毕业生（本科）<br> 
            <li> [2019/06]: 上海交通大学优秀毕业设计（一等奖）<br>
            <li> [2018/12]: 商汤奖学金<br> 
            <li> [2018/05]: 上海交通大学WISH奖学金<br> 
            <li> [2018/04]: 美国大学生数学建模大赛（一等奖）<br>
            <li> [2017-2022]: 上海交通大学学业优秀奖学金<br> <br> 
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>学术服务</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="0"><tbody>
          <li> 会议审稿人: CVPR, ICCV, ECCV, NeruIPS, ICML, ICLR, MICCAI <br>
          <li> 期刊审稿人: IEEE transactions on image processing (TIP), IEEE Transactions on Multimedia (TMM), IEEE transactions on neural networks and learning systems (TNNLS), IEEE Transactions on Medical Imaging (TMI), Expert systems with applications, Information fusion <br> <br> 
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>挑战赛</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/vand.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2308.04789">
                <papertitle>Multi-Scale Memory Comparison for Zero-/Few-Shot Anomaly Detection</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang*</strong>, 
              <a href="https://jjjaaafff.github.io/">Aofan Jiang*</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a> (* Equal Contribution)
              <br>
                <em><a href="https://sites.google.com/view/vand-cvpr23/challenge">VAND @ CVPR 2023</a> 挑战赛全球亚军</em>
              <p>
              利用多模态模型特征建立全局和个体的视觉和语言记忆库，在视觉异常和新颖性检测竞赛的少样本异常检测赛道获得第二名
              </p>
            </td>

            </tr> 
          </tr> 
        </tbody></table> <br>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>期刊论文</h2>
              </td>
            </tr>
          </tbody></table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          </tr> 
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/pipeline_ecg.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2408.17154">
                <papertitle>Self-supervised Anomaly Detection Pretraining Enhances Long-tail ECG Diagnosis</papertitle>
              </a>
              <br>
              <a href="https://jjjaaafff.github.io/">Aofan Jiang*</a>, 
              <strong>Chaoqin Huang*</strong>, Qing Cao, Yuchen Xu, Zi Zeng, Kang Chen, 
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a> (* 共同第一作者)
              <br>
                <em>Nature Communications </em> (under review，SCI，中科院1区Top)
              <p>
              提出了首个基于异常检测预训练的心电长尾诊断模型，在大规模的临床ECG数据集上对模型进行了严格验证。该数据集包含了2012年至2021年在上海真实医院环境中收集的超过一百万份ECG样本，涵盖116种不同的ECG类型。模型在诊断及异常检测/定位的内部和外部评估中均展现了显著的整体准确性提升。尤其是在处理稀有ECG类型时，该模型实现了94.7%的AUROC、92.2%的灵敏度和92.5%的特异性，明显优于传统方法。在前瞻性验证中，采用该模型辅助诊断的心脏病医生相比于单独工作的医生，诊断准确率提高6.7%，诊断完整性提升11.8%，诊断时间减少32%。
              </p>
            </td>
          </tr> 

          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/pami.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2406.08810">
                <papertitle>Few-Shot Anomaly Detection via Category-Agnostic Registration Learning</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=Z4bUA3EAAAAJ&hl=en">Haoyan Guan</a>,
              <a href="https://jjjaaafff.github.io/">Aofan Jiang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://nms.kcl.ac.uk/michael.spratling/">Michael Spratling</a>,
              <a href="https://sites.google.com/site/sitexinchaowang/">Xinchao Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              <br>
                <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </em> 2024 
              <br>
              (SCI，中科院1区Top)
              <p>
              针对现有方法需要为每个任务设计专用模型、昂贵且低效的问题，提出少样本异常检测方法：使通用模型能够应用于所有类别任务。在MVTec和MPDD基准上，将当前最先进技术分别提高了11.3%和8.3%
              </p>
            </td>
          </tr> 

          </tr> 
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/layerdecom.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10032792">
                <papertitle>Self-supervised Tumor Segmentation with Sim2Real Adaptation</papertitle>
              </a>
              <br>
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie</a>,
              <strong>Chaoqin Huang</strong>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              Xin Chen,
              <a href="https://www.qitian1987.com/">Qi Tian</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              
              <br>
                <em>IEEE Journal of Biomedical and Health Informatics (JBHI) </em> 2023 (SCI，中科院1区Top)
              <p>
              提出用于无监督肿瘤分割的两阶段Sim2Real训练方案，首先用模拟肿瘤预训练模型，然后采用自训练策略进行下游数据自适应。在评估BraTS2018用于脑肿瘤分割和LiTS2017用于肝肿瘤分割时，在无监督设置下实现了最先进的分割性能
              </p>
            </td>
          </tr> 

          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/SSM.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9779083">
                <papertitle>Self-Supervised Masking for Unsupervised Anomaly Detection and Localization</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=hQJ5hwMAAAAJ&hl=en&oi=ao">Qinwei Xu</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
              <a href="https://mediabrain.sjtu.edu.cn/yuwang/">Yu Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2023 (SCI，中科院1区Top)
              <p>
              提出自监督掩蔽（SSM）自监督学习方法用于无监督异常检测和定位。SSM增强图像修复网络的训练，同时提高推理时掩码预测的效率。提出渐进掩模细化方法，用于逐步揭示正常区域并定位异常区域。所提出的方法在视网膜OCT（医学诊断）和MVTec AD（工业缺陷检测）上分别达到98.3%和93.9%的AUC
              </p>
            </td>
         
            <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ARNet.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.10676">
                <papertitle>Attribute Restoration Framework for Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?hl=en&user=ZuQM_TUAAAAJ">Fei Ye*</a>,
              <strong>Chaoqin Huang*</strong>,
              <a href="http://www.jinkuncao.com/">Jinkun Cao</a>,
              <a href="https://scholar.google.com/citations?user=Qkx2FKoAAAAJ&hl=zh-CN">Maosen Li</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://www.mvig.org/">Cewu Lu</a> (* 共同第一作者)
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2022 (SCI，中科院1区Top) <font color="red"><strong>(ESI高被引)</strong></font>
              <p>
              提出将异常检测任务重新建模为自监督学习范式中的恢复任务，并基于恢复误差来区分正常数据和异常数据。通过强制网络恢复原始图像，网络学习与属性相关的语义特征。所提出的方法在多个基准数据集上，特别是在ImageNet上，显著优于现有技术，将表现最好的基线的AUC提高了10.1%
              </p>
            </td>
            </tr> 
        </tbody></table> <br>




        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>会议论文</h2>
              </td>
            </tr>
          </tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/MVFA_CVPR.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2403.12570">
                <papertitle>Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang*</strong>, 
              <a href="https://jjjaaafff.github.io/">Aofan Jiang*</a>, Jinghao Feng,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://sites.google.com/site/sitexinchaowang/">Xinchao Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a> (* 共同第一作者)
              <br>
                <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)</em> 2024 (CCF-A)  <font color="red"><strong>(Highlight)</strong></font>  <a href="https://github.com/MediaBrain-SJTU/MVFA-AD">code</a>
              <p>
              提出轻量级的多级适应和比较框架，利用CLIP模型进行医疗异常检测。将多个残差适配器集成到预先训练的视觉编码器中，从而逐步增强不同级别的视觉特征。 经过调整的特征在各种医疗数据类型中表现出较强的泛化能力，在未知的医疗模态和解剖区域的零样本场景中表现出色。
            </td>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/qvalue.jpg" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2405.17098">
                <papertitle>Q-value Regularized Transformer for Offline Reinforcement Learning</papertitle>
              </a>
              <br>
              <a href="https://charleshsc.github.io/">Shengchao Hu</a>,
              Ziqing Fan, 
              <strong>Chaoqin Huang*</strong>, 
              Li Shen, 
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://scholar.google.com/citations?user=RwlJNLcAAAAJ&hl=en&oi=ao">Dacheng Tao</a> 
              <br>
                <em>International Conference on Mechine Learning (ICML)</em> 2024 (CCF-A)
              <p>
              提出了Q值正则化变换器（QT），将变换器的轨迹建模能力与DP方法的最佳未来回报的可预测性相结合。QT学习一个动作值函数，并将一个最大化动作值的术语整合到CSM的训练损失中，旨在寻求与行为策略紧密一致的最佳动作。对D4RL基准数据集的实证评估表明，QT优于传统的DP和CSM方法，突显了QT在提升离线RL技术水平方面的潜力。
              </p>
            </td>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ECGAD.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2308.01639">
                <papertitle>Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://jjjaaafff.github.io/">Aofan Jiang*</a>,
              <strong>Chaoqin Huang*</strong>, 
              Qing Cao, Shuang Wu, Zi Zeng, Kang Chen,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a> (* 共同第一作者)
              <br>
                <em>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</em> 2023 (CCF-B) <font color="red"><strong>(Early accepted)</strong></font> <a href="https://github.com/MediaBrain-SJTU/ECGAD">code</a>
              <p>
              由于个体间的显著差异以及整体节律和局部形态均存在异常，检测心电图的异常尤其具有挑战性。通过模仿经验丰富的心脏病专家遵循的诊断过程，提出用于心电图异常检测和定位的多尺度交叉恢复框架，在提出的大规模心电图基准和其他两个著名的心电图数据集上实现了最先进的性能
              </p>
            </td>
         
            <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/RegAD.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-031-20053-3_18">
                <papertitle>Registration based Few-Shot Anomaly Detection</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=Z4bUA3EAAAAJ&hl=en">Haoyan Guan</a>,
              <a href="https://jjjaaafff.github.io/">Aofan Jiang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://nms.kcl.ac.uk/michael.spratling/">Michael Spratling</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              <br>
                <em>European Conference on Computer Vision (ECCV) </em> 2022 (CCF-B) <font color="red"><strong>(Oral Presentation)</strong></font> <a href="https://github.com/MediaBrain-SJTU/RegAD">code</a>
              <p>
              受人类检测异常的方法启发，利用图像配准作为代理任务来训练类别未知的异常检测模型。在测试期间，通过比较测试图像的配准特征及其相应的支撑正常图像来识别异常。在MVTec和MPDD少样本异常检测基准上，所提出的方法比最先进方法高3%-8%AUC
              </p>
            </td>

            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/DG_ISBI.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9761561">
                <papertitle>Semi-Supervised Domain Generalization for Medical Image Analysis</papertitle>
              </a>
              <br>
              <a href="https://frankzhangrp.github.io/">Ruipeng Zhang</a>,
              <a href="https://scholar.google.com/citations?user=hQJ5hwMAAAAJ&hl=en&oi=ao">Qinwei Xu</a>,
              <strong>Chaoqin Huang</strong>, 
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              <br>
                <em>IEEE International Symposium on Biomedical Imaging (ISBI)</em> 2022
              <p>
              提出通用的基于正则化的半监督域泛化方法，其中引入学习特征的稳定性和正交性作为学习目标的两个正则化因子。两种正则化因子都可以应用于标记数据和未标记数据
              </p>
            </td>

            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ESAD.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2012.04905">
                <papertitle>ESAD: End-to-end Deep Semi-supervised Anomaly Detection</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>, 
              <a href="https://scholar.google.com/citations?hl=en&user=ZuQM_TUAAAAJ">Fei Ye</a>,
              <a href="https://scholar.google.com/citations?user=hCr8Km8AAAAJ&hl=zh-CN">Peisen Zhao</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://www.qitian1987.com/">Qi Tian</a>
              <br>
                <em>British Machine Vision Conference (BMVC)</em> 2021
              <p>
              提出基于KL散度的半监督异常检测目标函数，其中互信息和熵构成了异常检测的积分目标函数。所提出方法在多个基准数据集上显著优于现有技术，包括医学诊断和几个经典的异常检测基准
              </p>
            </td>

            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ICIP.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9506079">
                <papertitle>Deep Unsupervised Image Anomaly Detection: An Information Theoretic Framework</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?hl=en&user=ZuQM_TUAAAAJ">Fei Ye</a>,
              <a href="https://huangjiezheng.com/">Huangjie Zheng</a>,
              <strong>Chaoqin Huang</strong>, 
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              <br>
                <em>IEEE International Conference on Image Processing (ICIP)</em> 2021
              <p>
              提出利用信息论进行异常检测的目标函数，该函数根据图像的联合分布及其表示来最大化正常和异常数据之间的距离。我们设法找到了它的下界，它对互信息和熵之间的权衡进行了加权，为无监督图像异常检测提供了一个新的信息论框架
              </p>
            </td>

            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/guided_filtering_diagram.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://drivingstereo-dataset.github.io/">
                <papertitle>DrivingStereo: A Large Dataset to Make Sense of Stereo Matching for Auto-Driving</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=6RaR1cQAAAAJ&hl=zh-CN">Guorun Yang</a>,
              <a href="https://scholar.google.com.hk/citations?user=tXuvWDYAAAAJ&hl=zh-CN">Xiao Song</a>,
              <strong>Chaoqin Huang</strong>, 
              <a href="https://scholar.google.com.au/citations?user=qfewonIAAAAJ&hl=en">Zhidong Deng</a>,
              <a href="https://scholar.google.com/citations?user=mwsxrm4AAAAJ&hl=en">Jianping Shi</a>,
              <a href="https://boleizhou.github.io/">Bolei Zhou</a>
              <br>
                <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)</em> 2019 (CCF-A)
              <p>
              构建新的大规模数据集DrivingStereo。它包含超过10万张图像，涵盖了一系列不同的驾驶场景。通过多帧激光雷达点的模型引导滤波策略产生高质量的视差标签
              </p>
            </td>

            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/rrm.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Pan_Recurrent_Residual_Module_CVPR_2018_paper.pdf">
                <papertitle>Recurrent Residual Module for Fast Inference in Videos</papertitle>
              </a>
              <br>
              <a href="http://people.csail.mit.edu/bpan/">Bowen Pan</a>,
              <a href="https://wuwei.io/">Wuwei Lin</a>,
              <a href="https://fang-xiaolin.github.io/">Xiaolin Fang</a>,
              <strong>Chaoqin Huang</strong>, 
              <a href="https://boleizhou.github.io/">Bolei Zhou</a>,
              <a href="https://www.mvig.org/">Cewu Lu</a>
              <br>
                <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR)</em> 2018 (CCF-A)
              <p>
              提出递归残差模块（RRM）来加速视频识别任务的CNN推理。该框架采用了一种新颖的设计，利用两个连续帧的中间特征图的相似性，大大减少了冗余计算
              </p>
            </td>

            </tr>
          </tr> 
        </tbody></table>






        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
