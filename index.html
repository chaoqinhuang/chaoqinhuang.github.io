<!DYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chaoqin Huang</title>
  
  <meta name="author" content="Chaoqin Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Chaoqin Huang (黄潮钦)</name>
              </p>
              <p>I am a joint PhD student working on computer vision at <a href="https://mediabrain.sjtu.edu.cn/">Shanghai Jiao Tong University</a> and <a href="http://www.lv-nus.org/"> National University of Singapore</a>. I received my bachelor degree from <a href="https://www.mvig.org/">Shanghai Jiao Tong University</a> in June 2019.
              </p>
	      <p>
		      My current research interest is in anomaly detection.
              </p>      
              <a href="huangchaoqin@sjtu.edu.cn">Email</a> &nbsp/&nbsp
              <a href="https://scholar.google.com/citations?user=BAZSE7wAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
              <a href="https://github.com/chaoqinhuang">Github</a>
              <p style="text-align:center">
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/chaoqinhuang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="image/chaoqinhuang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
	

  
</tbody></table>
	<br />
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading><b></bold>Journals</b></heading>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/SSM.png" width="250" height="80" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.06568">
                <papertitle>Self-Supervised Masking for Unsupervised Anomaly Detection and Localization</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=hQJ5hwMAAAAJ&hl=en&oi=ao">Qinwei Xu</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
              <a href="https://mediabrain.sjtu.edu.cn/yuwang/">Yu Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2022
              <p>
              We proposed a self-supervised learning approach named Self-Supervised Masking (SSM) for unsupervised anomaly detection and localization. SSM not only enhances the training of the inpainting network but also leads to great improvement in the efficiency of mask prediction at inference. We proposed a progressive mask refinement approach that progressively uncovers the normal regions and locates the anomalous regions. The proposed method outperforms several state-of-the-arts, achieving 98.3% AUC on Retinal-OCT (medical diagnosis) and 93.9% AUC on MVTec AD (industrial defect detection), respectively.
              </p>
            </td>
         
            <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ARNet.png" width="250" height="80" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.10676">
                <papertitle>Attribute Restoration Framework for Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?hl=en&user=ZuQM_TUAAAAJ">Fei Ye</a>,
              <strong>Chaoqin Huang</strong>,
              <a href="http://www.jinkuncao.com/">Jinkun Cao</a>,
              <a href="https://scholar.google.com/citations?user=Qkx2FKoAAAAJ&hl=zh-CN">Maosen Li</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://www.mvig.org/">Cewu Lu</a>
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2022, ESI Highly Cited Paper
              <p>
              We proposed to erase selected attributes from the original data and reformulate the anomaly detection task as a restoration task in the self-supervised learning paradigm, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. By forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. The proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUC of the top-performing baseline by 10.1%.
              </p>
            </td>
            </tr>
          </tr> 
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/layerdecom.png" width="250" height="80" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.10676">
                <papertitle>Self-supervised Tumor Segmentation with Sim2Real Adaptation</papertitle>
              </a>
              <br>
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie</a>,
              <strong>Chaoqin Huang</strong>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              Xin Chen,
              <a href="https://www.qitian1987.com/">Qi Tian</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              
              <br>
                <em>IEEE Journal of Biomedical and Health Informatics (JBHI) </em> 2023
              <p>
              We proposed a two-stage Sim2Real training regime for unsupervised tumor segmentation, where we first pre-train a model with simulated tumors and then adopt a self-training strategy for downstream data adaptation. When evaluating on BraTS2018 for brain tumor segmentation and LiTS2017 for liver tumor segmentation, we achieve state-of-the-art segmentation performance under the unsupervised setting.
              </p>
            </td>
          </tr>  
          </tr> 
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/pami.png" width="250" height="80" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
                <papertitle>Few-Shot Anomaly Detection via Category-Agnostic Registration Learning</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=Z4bUA3EAAAAJ&hl=en">Haoyan Guan</a>,
              Aofan Jiang,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://nms.kcl.ac.uk/michael.spratling/">Michael Spratling</a>,
              <a href="https://sites.google.com/site/sitexinchaowang/">Xinchao Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) </em> under review
              <p>
              Existing anomaly detection methods require a dedicated model for each category. Such a paradigm is computationally expensive and inefficient. This paper proposes the first FSAD method that requires no model fine-tuning for novel categories: enabling a single model to be applied to all categories. It improves the current state-of-the-art for FSAD by 11.3% and 8.3% on the MVTec and MPDD benchmarks, respectively.
              </p>
            </td>
          </tr> 
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
