<!DYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chaoqin Huang</title>
  
  <meta name="author" content="Chaoqin Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Chaoqin Huang (黄潮钦)</name>
              </p>
              <p>I am a joint PhD student working on computer vision at <a href="https://mediabrain.sjtu.edu.cn/">Shanghai Jiao Tong University</a> and <a href="http://www.lv-nus.org/"> National University of Singapore</a>. I received my bachelor degree from <a href="https://www.mvig.org/">Shanghai Jiao Tong University</a> in June 2019.
              </p>
	      <p>
		      My current research interest is in anomaly detection on industrial defect detection and medical diagnosis.
              </p>      
              <a href="chaoqinhuang.pdf">CV</a> &nbsp/&nbsp
              <a href="huangchaoqin@sjtu.edu.cn">Email</a> &nbsp/&nbsp
              <a href="https://scholar.google.com/citations?user=BAZSE7wAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
              <a href="https://github.com/chaoqinhuang">Github</a>
              <p style="text-align:center">
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="image/chaoqinhuang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="image/chaoqinhuang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
	

  
</tbody></table>
	<br />
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading><b></bold>Journals</b></heading>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/SSM.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.06568">
                <papertitle>Self-Supervised Masking for Unsupervised Anomaly Detection and Localization</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=hQJ5hwMAAAAJ&hl=en&oi=ao">Qinwei Xu</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a>,
              <a href="https://mediabrain.sjtu.edu.cn/yuwang/">Yu Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2022
              <p>
              We proposed a self-supervised learning approach named Self-Supervised Masking (SSM) for unsupervised anomaly detection and localization. SSM not only enhances the training of the inpainting network but also leads to great improvement in the efficiency of mask prediction at inference. We proposed a progressive mask refinement approach that progressively uncovers the normal regions and locates the anomalous regions. The proposed method outperforms several state-of-the-arts, achieving 98.3% AUC on Retinal-OCT (medical diagnosis) and 93.9% AUC on MVTec AD (industrial defect detection), respectively.
              </p>
            </td>
         
            <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ARNet.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.10676">
                <papertitle>Attribute Restoration Framework for Anomaly Detection</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?hl=en&user=ZuQM_TUAAAAJ">Fei Ye*</a>,
              <strong>Chaoqin Huang*</strong>,
              <a href="http://www.jinkuncao.com/">Jinkun Cao</a>,
              <a href="https://scholar.google.com/citations?user=Qkx2FKoAAAAJ&hl=zh-CN">Maosen Li</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://www.mvig.org/">Cewu Lu</a> (* Equal Contribution)
              
              <br>
                <em>IEEE Transactions on Multimedia (TMM) </em> 2022 <font color="red"><strong>(ESI Highly Cited Paper)</strong></font>
              <p>
              We proposed to erase selected attributes from the original data and reformulate the anomaly detection task as a restoration task in the self-supervised learning paradigm, where the normal and the anomalous data are expected to be distinguishable based on restoration errors. By forcing the network to restore the original image, the semantic feature embeddings related to the erased attributes are learned by the network. The proposed method significantly outperforms several state-of-the-arts on multiple benchmark datasets, especially on ImageNet, increasing the AUC of the top-performing baseline by 10.1%.
              </p>
            </td>
            </tr>
          </tr> 
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/layerdecom.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/10032792">
                <papertitle>Self-supervised Tumor Segmentation with Sim2Real Adaptation</papertitle>
              </a>
              <br>
              <a href="https://xiaoman-zhang.github.io/">Xiaoman Zhang</a>,
              <a href="https://weidixie.github.io/">Weidi Xie</a>,
              <strong>Chaoqin Huang</strong>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              Xin Chen,
              <a href="https://www.qitian1987.com/">Qi Tian</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              
              <br>
                <em>IEEE Journal of Biomedical and Health Informatics (JBHI) </em> 2023
              <p>
              We proposed a two-stage Sim2Real training regime for unsupervised tumor segmentation, where we first pre-train a model with simulated tumors and then adopt a self-training strategy for downstream data adaptation. When evaluating on BraTS2018 for brain tumor segmentation and LiTS2017 for liver tumor segmentation, we achieve state-of-the-art segmentation performance under the unsupervised setting.
              </p>
            </td>
          </tr>  
          </tr> 
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/pami.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
                <papertitle>Few-Shot Anomaly Detection via Category-Agnostic Registration Learning</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=Z4bUA3EAAAAJ&hl=en">Haoyan Guan</a>,
              Aofan Jiang,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>,
              <a href="https://nms.kcl.ac.uk/michael.spratling/">Michael Spratling</a>,
              <a href="https://sites.google.com/site/sitexinchaowang/">Xinchao Wang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>
              <br>
                <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI) </em> under review
              <p>
              Existing anomaly detection methods require a dedicated model for each category. Such a paradigm is computationally expensive and inefficient. This paper proposes the first FSAD method that requires no model fine-tuning for novel categories: enabling a single model to be applied to all categories. It improves the current state-of-the-art for FSAD by 11.3% and 8.3% on the MVTec and MPDD benchmarks, respectively.
              </p>
            </td>
          </tr> 
        </tbody></table>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading><b></bold>Conferences</b></heading>
          <tr onmouseout="ld_stop()" onmouseover="ld_start()">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/ECGAD.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2308.01639">
                <papertitle>Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection</papertitle>
              </a>
              <br>
              Aofan Jiang*,
              <strong>Chaoqin Huang*</strong>, 
              Qing Cao, Shuang Wu, Zi Zeng, Kang Chen,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang </a> (* Equal Contribution)
              <br>
                <em>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</em> 2023 (Early accepted)
              <p>
              Detecting anomalies in Electrocardiogram (ECG) data is particularly challenging due to the substantial inter-individual differences and the presence of anomalies in both global rhythm and local morphology. Imitating the diagnostic process followed by experienced cardiologists, we proposed a novel multi-scale cross-restoration framework for ECG anomaly detection and localization, achieving state-of-the-art performance on our proposed large-scale ECG benchmark and two other well-known ECG datasets.
              </p>
            </td>
         
            <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
            <td style="padding:0px;width:25%;vertical-align:middle">
              <img src="image/RegAD.png" width="250" style="border-style: none">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.10676">
                <papertitle>Registration based Few-Shot Anomaly Detection</papertitle>
              </a>
              <br>
              <strong>Chaoqin Huang</strong>,
              <a href="https://scholar.google.com/citations?user=Z4bUA3EAAAAJ&hl=en">Haoyan Guan</a>,
              Aofan Jiang,
              <a href="https://mediabrain.sjtu.edu.cn/yazhang/">Ya Zhang</a>,
              <a href="https://nms.kcl.ac.uk/michael.spratling/">Michael Spratling</a>,
              <a href="https://mediabrain.sjtu.edu.cn/members/">Yanfeng Wang</a>
              <br>
                <em>European Conference on Computer Vision (ECCV) </em> 2022 <font color="red"><strong>(Oral Presentation)</strong></font>
              <p>
              We considered few-shot anomaly detection (FSAD), a practical yet under-studied setting for anomaly detection, where only a limited number of normal images are provided for each category at training. Inspired by how humans detect anomalies, i.e., comparing an image in question to normal images, we leveraged registration, an image alignment task that is inherently generalizable across categories, as the proxy task, to train a category-agnostic anomaly detection model. During testing, the anomalies are identified by comparing the registered features of the test image and its corresponding support (normal) images. Experimental results have shown that the proposed method outperforms the state-of-the-art FSAD methods by 3%-8% in AUC on the MVTec and MPDD benchmarks.
              </p>
            </td>
            </tr>
          </tr> 
        </tbody></table>








        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>Awards</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="0"><tbody>
            <li> [2022/12]: National Scholarship of China <br> <br>
            <li> [2019/06]: Outstanding Graduate of Shanghai Jiao Tong University <br> <br>
            <li> [2019/06]: 1st Outstanding Graduation Thesis Award of Computer Science in SJTU <br> <br>
            <li> [2018/12]: SenseTime Scholarship <br> <br>
            <li> [2018/05]: Shanghai Jiao Tong University WISH Scholarship <br> <br>
            <li> [2018/04]: Meritorious Winner of Mathematical Contest In Modeling 2018 <br> <br>
            <li> [2017-2022]: Shanghai Jiao Tong University Academic Excellent Scholarship <br> <br>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="0"><tbody>
            <tr>
              <td>
                <h2>Services</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="0"><tbody>
          <li> Conference Reviewer: NeruIPS, CVPR, ICCV, ECCV, MICCAI <br> <br>
          <li> Journal Reviewer: TMM <br> <br>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
		Based on a template by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
